{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJck5kUJfC2f"
      },
      "source": [
        "# SpeedScribe Colab\n",
        "\n",
        "___\n",
        "\n",
        "<a href=\"https://fakeyou.com/\"><img src=\"https://fakeyou.com/fakeyou/FakeYou-Logo.png\" alt=\"FakeYou Logo. Click here to go to the official website.\"></a>\n",
        "\n",
        "\n",
        "This is a ASR transcription notebook for Tacotron2 and similar TTS models such as VITS\n",
        "\n",
        "Notebook author - [justinjohn-03](https://github.com/justinjohn0306)\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SxvLXqFnx_Mk"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Clone GitHub repository\n",
        "!git clone https://github.com/justinjohn0306/SpeedScribe.git\n",
        "!pip install faster-whisper ctranslate2==4.4.0\n",
        "\n",
        "# Add the repository path to Python’s search path\n",
        "import sys\n",
        "sys.path.append('/content/SpeedScribe')\n",
        "\n",
        "# Import the ASR function from the script\n",
        "from SpeedScribe import execute_asr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9pOuEJJJyBiV"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Choose the source of the WAV files\n",
        "import os\n",
        "source_option = \"Google Drive\"  # @param [\"Google Drive\", \"Local\"]\n",
        "\n",
        "if source_option == \"Google Drive\":\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Provide the path to the ZIP file in Google Drive\n",
        "    zip_file = \"/content/drive/MyDrive/path_to_your_zip_file.zip\"  # @param {type:\"string\"}\n",
        "\n",
        "else:\n",
        "    # Upload the ZIP file locally\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    zip_file = next(iter(uploaded))  # Get the uploaded file name\n",
        "\n",
        "# Get the name of the ZIP file without the extension\n",
        "zip_filename = os.path.splitext(os.path.basename(zip_file))[0]\n",
        "\n",
        "# Set the output folder based on the ZIP file's name\n",
        "output_folder = f\"/content/{zip_filename}\"\n",
        "\n",
        "# Function to handle unzipping\n",
        "def unzip_files(zip_file, extract_to=\"./dataset\"):\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Files extracted to {extract_to}\")\n",
        "    return extract_to\n",
        "\n",
        "extract_to = unzip_files(zip_file, extract_to=output_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CKvleH9yyEJu"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Define the parameters for transcription\n",
        "\n",
        "# Available model sizes\n",
        "model_size = \"faster-whisper-large-v3-turbo-ct2\"  # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\", \"faster-whisper-large-v3-turbo-ct2\"]\n",
        "\n",
        "# Select the language for transcription\n",
        "language_name = \"English\"  # @param [\"Automatic Detection\", \"Afrikaans\", \"Amharic\", \"Arabic\", \"Assamese\", \"Azerbaijani\", \"Bashkir\", \"Belarusian\", \"Bulgarian\", \"Bengali\", \"Tibetan\", \"Breton\", \"Bosnian\", \"Catalan\", \"Czech\", \"Welsh\", \"Danish\", \"German\", \"Greek\", \"English\", \"Spanish\", \"Estonian\", \"Basque\", \"Persian\", \"Finnish\", \"Faroese\", \"French\", \"Galician\", \"Gujarati\", \"Hausa\", \"Hawaiian\", \"Hebrew\", \"Hindi\", \"Croatian\", \"Haitian Creole\", \"Hungarian\", \"Armenian\", \"Indonesian\", \"Icelandic\", \"Italian\", \"Japanese\", \"Javanese\", \"Georgian\", \"Kazakh\", \"Khmer\", \"Kannada\", \"Korean\", \"Latin\", \"Luxembourgish\", \"Lingala\", \"Lao\", \"Lithuanian\", \"Latvian\", \"Malagasy\", \"Maori\", \"Macedonian\", \"Malayalam\", \"Mongolian\", \"Marathi\", \"Malay\", \"Maltese\", \"Burmese\", \"Nepali\", \"Dutch\", \"Norwegian Nynorsk\", \"Norwegian\", \"Occitan\", \"Punjabi\", \"Polish\", \"Pashto\", \"Portuguese\", \"Romanian\", \"Russian\", \"Sanskrit\", \"Sindhi\", \"Sinhala\", \"Slovak\", \"Slovenian\", \"Shona\", \"Somali\", \"Albanian\", \"Serbian\", \"Sundanese\", \"Swedish\", \"Swahili\", \"Tamil\", \"Telugu\", \"Tajik\", \"Thai\", \"Turkmen\", \"Tagalog\", \"Turkish\", \"Tatar\", \"Ukrainian\", \"Urdu\", \"Uzbek\", \"Vietnamese\", \"Yiddish\", \"Yoruba\", \"Chinese\", \"Cantonese\"]\n",
        "\n",
        "# Define the precision\n",
        "precision = \"float16\"  # @param [\"float16\", \"float32\", \"int8\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Mp1MYLrkyGcj"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Start the transcription process\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"huggingface_hub\")\n",
        "\n",
        "# Get the name of the ZIP file without the extension\n",
        "zip_filename = os.path.splitext(os.path.basename(zip_file))[0]\n",
        "\n",
        "# Set the output folder to be based on the ZIP file's name\n",
        "output_folder = f\"/content/{zip_filename}\"\n",
        "\n",
        "# Run the transcription process\n",
        "output_file_path = execute_asr(extract_to, output_folder, model_size, language_name, precision)\n",
        "\n",
        "# Set the final output file path\n",
        "final_output_file_path = os.path.join(output_folder, f\"{zip_filename}.txt\")\n",
        "os.rename(output_file_path, final_output_file_path)\n",
        "\n",
        "# Download the transcription file\n",
        "from google.colab import files\n",
        "files.download(final_output_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2oQntuYFBfp"
      },
      "source": [
        "# Transcribe using SenseVoice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zFWNaJxfFCtv"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Clone GitHub repository\n",
        "!git clone https://github.com/justinjohn0306/SpeedScribe.git\n",
        "!pip install funasr==1.1.3 modelscope\n",
        "\n",
        "# Add the repository path to Python’s search path\n",
        "import sys\n",
        "sys.path.append('/content/SpeedScribe')\n",
        "\n",
        "# Import the ASR function from the script\n",
        "from sensevoice import execute_asr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-Cnuvw8QFJsm"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Choose the source of the WAV files\n",
        "import os\n",
        "source_option = \"Google Drive\"  # @param [\"Google Drive\", \"Local\"]\n",
        "\n",
        "if source_option == \"Google Drive\":\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Provide the path to the ZIP file in Google Drive\n",
        "    zip_file = \"/content/drive/MyDrive/test.zip\"  # @param {type:\"string\"}\n",
        "\n",
        "else:\n",
        "    # Upload the ZIP file locally\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    zip_file = next(iter(uploaded))  # Get the uploaded file name\n",
        "\n",
        "# Get the name of the ZIP file without the extension\n",
        "zip_filename = os.path.splitext(os.path.basename(zip_file))[0]\n",
        "\n",
        "# Set the output folder based on the ZIP file's name\n",
        "output_folder = f\"/content/{zip_filename}\"\n",
        "\n",
        "# Function to handle unzipping\n",
        "def unzip_files(zip_file, extract_to=\"./dataset\"):\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Files extracted to {extract_to}\")\n",
        "    return extract_to\n",
        "\n",
        "extract_to = unzip_files(zip_file, extract_to=output_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9Q0j2OLgFpBe"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Define the parameters for transcription\n",
        "\n",
        "# Select the language for transcription\n",
        "language_name = \"ja\"  # @param [\"auto\", \"zh\", \"en\", \"ja\", \"yue\", \"ko\"]\n",
        "\n",
        "# Define the precision\n",
        "device = \"cuda\"  # @param [\"cuda\", \"cpu\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "vyiwXvODGBm2"
      },
      "outputs": [],
      "source": [
        "# @markdown ### Start the transcription process\n",
        "import os\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "logging.getLogger(\"modelscope\").setLevel(logging.ERROR)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"modelscope\")\n",
        "\n",
        "zip_filename = os.path.splitext(os.path.basename(zip_file))[0]\n",
        "\n",
        "output_folder = \"/content/output_transcriptions\"\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "output_file_path = execute_asr(extract_to, output_folder, language_name, device)\n",
        "\n",
        "final_output_file_path = os.path.join(output_folder, f\"{zip_filename}.txt\")\n",
        "\n",
        "os.rename(output_file_path, final_output_file_path)\n",
        "\n",
        "# Download the transcription file\n",
        "from google.colab import files\n",
        "files.download(final_output_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG0GMRkQhJu5"
      },
      "source": [
        "# **Misc**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zGRc2xZ7hMoY"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Dot-processing for unprocessed transcripts**\n",
        "#@markdown This section allows you to add dots at the end of each line in your transcript file.\n",
        "#@markdown You can upload the transcript file from your local system and process it here.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Upload your transcript file from your local system\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    input_filename = next(iter(uploaded))\n",
        "    output_filename = \"processed_\" + input_filename\n",
        "\n",
        "    # Function to ensure each line in the transcript ends with a dot\n",
        "    def DotsAdderTotxtFile(input_file, output_file):\n",
        "        with open(input_file, 'r') as f_input, open(output_file, 'w') as f_output:\n",
        "            for line in f_input:\n",
        "                line = line.strip()\n",
        "                # Add a dot only if the line doesn't end with '.', '?', or '!'\n",
        "                if not line.endswith(('.', '?', '!')):\n",
        "                    line += '.'\n",
        "                f_output.write(line + '\\n')\n",
        "\n",
        "    # Call the function with the uploaded file\n",
        "    DotsAdderTotxtFile(input_filename, output_filename)\n",
        "\n",
        "    print(f\"Dots Processing complete! Processed file: {output_filename}\")\n",
        "    print(\"You can download the processed file now.\")\n",
        "\n",
        "    # Provide download link for the processed file\n",
        "    files.download(output_filename)\n",
        "else:\n",
        "    print(\"No file uploaded. Please upload a transcript file to process.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KG0GMRkQhJu5"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
